# FROM ubuntu:22.04
FROM base-env
# Evita prompts interactivos
ENV DEBIAN_FRONTEND=noninteractive
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64

ENV SPARK_VERSION=3.3.2
ENV SPARK_FILE=3.3.2-bin-hadoop3
ENV HADOOP_VERSION=3
ENV SPARK_HOME=/opt/spark

ENV PATH=$JAVA_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH

# Pyspark
ENV PYTHONPATH=/opt/spark/python:/opt/spark/python/lib/py4j-*.zip

ENV PYSPARK_PYTHON=python3
ENV PYSPARK_DRIVER_PYTHON=python3

# Jupiter
# ENV PYSPARK_DRIVER_PYTHON=jupyter
# ENV PYSPARK_DRIVER_PYTHON_OPTS="notebook --ip=0.0.0.0 --no-browser --allow-root"


RUN apt-get update && \
    apt-get install -y \
    openjdk-11-jdk \
    wget \
    curl \
    python3 \
    python3-pip && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

RUN wget https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz && \
    tar -xzf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz && \
    mv spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /opt/spark && \
    rm spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz


# PY4J correcto
RUN PY4J_ZIP=$(ls /opt/spark/python/lib/py4j-*.zip) && \
    echo "export PYTHONPATH=/opt/spark/python:$PY4J_ZIP" >> /etc/profile.d/spark.sh

COPY requirements_05_week.txt /tmp/requirements_05_week.txt
RUN pip3 install --no-cache-dir -r /tmp/requirements_05_week.txt

WORKDIR /opt/notebooks

EXPOSE 8888 4040

CMD ["jupyter-notebook", "--ip=0.0.0.0", "--port=8888", "--no-browser", "--allow-root", "--NotebookApp.token=''", "--NotebookApp.password=''"]
